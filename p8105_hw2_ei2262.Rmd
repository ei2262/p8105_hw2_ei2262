---
title: "p8105_hw2_ei2262"
output: github_document
---

# Problem 0
```{r load_libraries, include = FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
```

# Problem 1

This was my attempt at solving Problem 1:
```{r}
clean_nyctransit =  read_csv(
    "./hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  pivot_longer(
    route1:route11,
    names_to = "routes",
    values_to = "routes served"
  ) %>% 
  mutate(
    entry = as.logical(entry)
  )
```
Importing and cleaning data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`.

## Problem 1 Solution

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r, results = "hide"}
trans_ent = 
  read_csv(
    "./hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r, results = "hide"}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r, results = "hide"}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r, results = "hide"}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r, results = "hide"}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

# Problem 2

### Importing and cleaning up **Mr. Trash Wheel** dataset

```{r}
mr_trash_wheel = read_excel('./hw2/Trash-Wheel-Collection-Data.xlsx', sheet = "Mr. Trash Wheel", range = "A2:N550") %>% 
  janitor::clean_names() %>%
  drop_na(c("dumpster")) %>% 
  mutate(
    sports_balls = round(as.integer(sports_balls)),
    trash_wheel = as.character("mister")
  )
```

The process began with data import. I used `read_excel` to import the Excel file and selected the `Mr.Trash Wheel` sheet. When I examined the dataset, there were columns that were non-data entries. I omitted these columns by selecting the appropriate range within the excel sheet to import. 

I then dropped any rows that had `NA` and did not include dumpster-specific data. I used `janitor::clean_names()` to clean up the variable names. To round the number of sports balls to the nearest integer and convert the result to an integer, I used `mutate` to overwrite the existing `sports_balls` variable and used the `as.integer` and `round` functions.

In order to distinguish this dataset from Professor Trash Wheel, I created the variable `trash_wheel` and labeled all the data in Mr. Trash Wheel as `mister`.


### Importing, Cleaning, and Organizing data for Professor Trash Wheel

```{r}
professor_trash_wheel = read_excel('./hw2/Trash-Wheel-Collection-Data.xlsx', sheet = "Professor Trash Wheel", range = "A2:N117") %>% 
  drop_na() %>%  
  janitor::clean_names() %>% 
  mutate(
    sports_balls = round(as.integer(sports_balls)),
    trash_wheel = as.character("professor")
  )
```

In order to produce a single, tidy dataset, I applied the same importing, cleaning, and organizing steps used on Mr. Trash Wheel's dataset to the Professor Trash Wheel's dataset. The only difference is the variable `trash_wheel`, which is labeled `professor` for the Professor Trash Wheel observations.


#### Producing a Single, Tidy Dataset: Mr. Trash Wheel and Professor Trash Wheel

```{r, collapse = TRUE}
combined_trash_wheel = full_join(
  x = mr_trash_wheel, 
  y = professor_trash_wheel, 
  by = c("dumpster", "month", "year", "date", "weight_tons", "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts", "glass_bottles", "grocery_bags", "chip_bags", "sports_balls", "homes_powered", "trash_wheel"))

combined_trash_wheel
```
`combined_trash_wheel` is the single, tidy dataset that was created after combining  `mr_trash_wheel` and `professor_trash_wheel` using `full_join`. There are 15 variables and 517 observations in `combined_trash_wheel`. Key variables include `trash_wheel`, used to distinguish which dataset the observation belongs to (`mr_trash_wheel` or `professor_trash_wheel`), `dumpster`, identification of each dumpster, `date` of collection, which ranges from *`r min(combined_trash_wheel$date)`* to *`r max(combined_trash_wheel$date)`*, and `weight_tons`, which is the weight of litter (in tons) contained in each dumpster. Other variables include the type of litter collected, such as plastic bottles, polystyrene, cigarette butts, glass bottles, and grocery bags,the number of `homes_powered` after waste is taken to energy plants, which ranges from `r min(combined_trash_wheel$homes_powered)` to `r max(round(combined_trash_wheel$homes_powered, digits = 1))`.


##### What was the total weight of trash collected by Professor Trash Wheel?

```{r}
combined_trash_wheel %>% 
  group_by(trash_wheel == "professor") %>% 
  summarize(sum(weight_tons))
```
The total weight of trash collected by Professor Trash Wheel was **1430 tons**.


##### What was the total number of sports balls collected by Mr. Trash Wheel in 2020?

```{r}
combined_trash_wheel %>% 
  group_by(trash_wheel == "mister", year == 2020) %>% 
  summarize(sum(sports_balls))
```
The total number of sports balls collected by Mr. Trash Wheel in 2020 was **771 balls**.


# Problem 3

##### Cleaning the data in `pols.month.csv`
```{r}
pols = read_csv("./fivethirtyeight/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon,c('year', 'month', 'date'),'-') %>% 
  mutate(
    month = as.integer(month),
    month = month.abb[month],
    president = prez_gop + prez_dem
  ) %>% 
  select(-prez_gop,-prez_dem,-date)
```
To clean the data in `pols-month.csv`, I separated the variable `mon` by `year`, `month`, and `date`. I converted the `month` variable into an integer to replace the month number with the abbrevations of each month. Abbreviations was chosen to align with the `unemployment.csv` dataset. I created the new variable `president`, which combines `prez_gop` and `prez_dem`. I used `select` to remove `prez_gop`, `prez_dem`, and `date`.


##### Cleaning the data in `snp.csv`
```{r}
snp = read_csv("./fivethirtyeight/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, format = "%m/%d/%y")) %>% 
  separate(date,c("year", "month","date"), "-") %>% 
  mutate(
    month = as.integer(month),
    month = month.abb[month]
  ) %>% 
  select(-date) %>% 
  select(year, month, everything())
```
To clean the data in `snp.csv`, I reformatted the date in the `csv` file to get the year in the format desired ("YYYY"). After reformatting the date, I was able to separate by `year`, `month`, and `date`. In order to convert the month number to abbreviations of the months, I used the same method used for cleaning th `pols-month.csv` dataset. `select` was used to remove `date` and rearrange the columns to have `year` and `month` the first two columns. 


##### Cleaning the data in `unemployment.csv`

```{r}
unemployment = read_csv("./fivethirtyeight/unemployment.csv") %>% 
  pivot_longer(
    col = !Year,
    names_to = "month",
    values_to = "percentage"
  ) %>% 
  janitor::clean_names()
```
To clean the `unemployment.csv` dataset, I used `pivot_longer` to create a column for the abbreviated `month` names and the `percentage` of unemployment in each associated month and year. The dataset is also in the same arrangement as `pols` and `snp` to ensure the datasets join correctly.

##### Joining `snp`, `pols`, and `unemployment`

```{r}
fivethirtyeight = left_join(pols, snp, by = c("year", "month"))
```
I first joined the `snp` and `pols` dataset by using `left_join` to take observations in `snp` and and merge them into `pols`. I joined the two datasets by columns `year` and `month`.

```{r}
fivethirtyeight_merged = merge(fivethirtyeight, unemployment, by = c("year", "month"))
```
I merged `fivethirtyeight` with `unemployment` using merge. The datasets were merged by `year` and `month`.


##### Description of `fivethirtyeight_merged`

`fivethirtyeight_merged` contains three datasets: `pols`, `snp`, and `unemployment`.

1. `pols`: this dataset contains data related to the number of national politicians who are democratic or republican at any given month and year.
2. `snp`: this dataset contains data related to the closing values of the Standard & Poor's stock market index (S&P) in a specific month and year.
3. `unemployment`: this dataset contains data related to the percentage of unemployment in a given month of a given year.

*Note: The year 1974 in the `pols` datatset has a value of 2 for the variable `president` because there were 2 presidents in one year. This is when President Nixon resigned and President Ford took office. Both presidents were Republicans.

After combining the three datasets, `fivethirtyeight_merged` contains `r nrow(fivethirtyeight_merged)` rows and `r ncol(fivethirtyeight_merged)` variables. Variables include `r ls(fivethirtyeight_merged)`. The `year` ranges from `r min(fivethirtyeight_merged$year)` to `r max(fivethirtyeight_merged$year)`.

